{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libirary\n",
    "import warnings\n",
    "import shap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC, GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn.neighbors._base\n",
    "# before import missingpy, you must run the following codes\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "# Please change the following path to the file you want to analyze\n",
    "raw_data = pd.read_csv(\"somepath/yourfile.csv\")\n",
    "\n",
    "\n",
    "X = raw_data.iloc[:, raw_data.columns != 'unmet ADL needs']\n",
    "y = raw_data.iloc[:, raw_data.columns == 'unmet ADL needs']\n",
    "cols = X.columns\n",
    "\n",
    "# imputing missing data\n",
    "imputer = MissForest()\n",
    "imputer.fit(X)\n",
    "X2 = imputer.transform(X)\n",
    "X2 = np.round(X2)\n",
    "X = pd.DataFrame(X2, columns=cols)\n",
    "\n",
    "# spliting data\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=11)\n",
    "\n",
    "for i in [Xtrain, Xtest, ytrain, ytest]:\n",
    "    i.index = range(i.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the best parameters of logistic regression model\n",
    "# it will last a few minutes\n",
    "param_gird = {'C': list(np.linspace(0.001, 1, 50)),\n",
    "              'solver': ['liblinear', 'sag', 'newton-cg', 'lbfgs']}\n",
    "\n",
    "\n",
    "LRTC = LR()\n",
    "GS = GridSearchCV(LRTC, param_gird, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "GS.fit(Xtrain, ytrain)\n",
    "bestParams_LR = GS.best_params_\n",
    "print(bestParams_LR, GS.best_score_)\n",
    "\n",
    "# printing performance of logistic regression model with the best parameters\n",
    "clf = LR(**bestParams_LR)\n",
    "# using train dataset to train model\n",
    "clf.fit(Xtrain, ytrain)\n",
    "# using test dataset to test the performance of model\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the best parameters of gradient boosting model\n",
    "# it will last a few minutes\n",
    "def gbc_cv(n_estimators, max_depth, max_features, min_samples_leaf, min_samples_split, learning_rate):\n",
    "    gbc = GBC(n_estimators=round(n_estimators), max_depth=round(max_depth),\n",
    "              max_features=max_features, min_samples_leaf=round(min_samples_leaf),\n",
    "              min_samples_split=round(min_samples_split), learning_rate=learning_rate)\n",
    "    roc_aucs = cross_val_score(gbc, Xtrain, ytrain, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "    return np.mean(roc_aucs)\n",
    "\n",
    "gbc_op = BayesianOptimization(\n",
    "    gbc_cv,\n",
    "    {'n_estimators': (1, 200),\n",
    "     'max_depth': (1, 20),\n",
    "     'max_features': (0.1, 1.0),\n",
    "     'min_samples_leaf': (1, 20),\n",
    "     'min_samples_split': (2, 20),\n",
    "     'learning_rate': (0.001, 1)},\n",
    "    random_state=2023\n",
    ")\n",
    "\n",
    "gbc_op.maximize(init_points=10, n_iter=50)\n",
    "bestParams_GBC = gbc_op.max['params']\n",
    "# Rounding a floating-point value\n",
    "for k, v in bestParams_GBC.items():\n",
    "    if k not in ['max_features', 'learning_rate']:\n",
    "        bestParams_GBC[k] = round(v)\n",
    "print(bestParams_GBC, gbc_op.max['target'])\n",
    "\n",
    "# printing performance of gradient boosting model with the best parameters\n",
    "clf = GBC(**bestParams_GBC)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the best parameters of naïve bayes model\n",
    "param_gird = {'var_smoothing': list(np.linspace(0.01, 1, 100))}\n",
    "nb = NB()\n",
    "GS = GridSearchCV(nb, param_gird, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "GS.fit(Xtrain, ytrain)\n",
    "bestParams_NB = GS.best_params_\n",
    "print(bestParams_NB, GS.best_score_)\n",
    "\n",
    "# printing performance of naïve bayes model\n",
    "clf = NB(**bestParams_NB)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the best parameters of decision tree model\n",
    "# it will last a few minutes\n",
    "param_gird = {'max_depth': np.arange(1, 20, 2),\n",
    "              'max_features': np.arange(1, 20, 2),\n",
    "              'min_samples_leaf': np.arange(2, 20, 2),\n",
    "              'min_samples_split': np.arange(4, 20, 2)}\n",
    "dt = DT()\n",
    "GS = RandomizedSearchCV(dt, param_gird, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "GS.fit(Xtrain, ytrain)\n",
    "bestParams_DT = GS.best_params_\n",
    "print(bestParams_DT, GS.best_score_)\n",
    "\n",
    "# printing performance of decision tree model\n",
    "clf = DT(**bestParams_DT)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the best parameters of KNN model\n",
    "param_gird = {'n_neighbors': list(np.arange(1, 30))}\n",
    "knn = KNN()\n",
    "GS = GridSearchCV(knn, param_gird, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "GS.fit(Xtrain, ytrain)\n",
    "bestParams_KNN = GS.best_params_\n",
    "print(bestParams_KNN, GS.best_score_)\n",
    "\n",
    "# printing performance of KNN model\n",
    "clf = KNN(**bestParams_KNN)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using BayesianOptimization to search the best parameters of random forest model\n",
    "def rfc_cv(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    clf = RFC(n_estimators=round(n_estimators),  min_samples_split=round(min_samples_split),\n",
    "              max_features=max_features,\n",
    "              max_depth=round(max_depth), random_state=2023)\n",
    "    \n",
    "    # 10-fold cross validation\n",
    "    roc_aucs = cross_val_score(clf, Xtrain, ytrain, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "    return np.mean(roc_aucs)\n",
    "\n",
    "rfc_op = BayesianOptimization(\n",
    "    rfc_cv,\n",
    "    {'n_estimators': (10, 200),\n",
    "     'min_samples_split': (5, 25),\n",
    "     'max_features': (0.1, 0.999),\n",
    "     'max_depth': (3, 20)},\n",
    "    random_state=2023\n",
    ")\n",
    "\n",
    "rfc_op.maximize(init_points=10, n_iter=50)\n",
    "bestParams_RFC = rfc_op.max['params']\n",
    "# Rounding a floating-point value\n",
    "for k, v in bestParams_RFC.items():\n",
    "    if k != 'max_features':\n",
    "        bestParams_RFC[k] = round(v)\n",
    "print(bestParams_RFC, rfc_op.max['target'])\n",
    "\n",
    "# printing performance of random forest model with the best parameters\n",
    "clf = RFC(random_state=2023, **bestParams_RFC)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "yproba = clf.predict_proba(Xtest)\n",
    "print('Accuracy:', clf.score(Xtest, ytest))\n",
    "print('Precision:', metrics.precision_score(ytest, ypred))\n",
    "print('Recall:', metrics.recall_score(ytest, ypred))\n",
    "print('F1 score:', metrics.f1_score(ytest, ypred))\n",
    "roc_auc = metrics.roc_auc_score(ytest, yproba[:, 1])\n",
    "print('AUROC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting ROC curve\n",
    "plt.figure(figsize=(20, 16))\n",
    "model_rfc = RFC(random_state=2023, **bestParams_RFC)\n",
    "model_rfc.fit(Xtrain, ytrain)\n",
    "y_pred_rfc = model_rfc.predict_proba(Xtest)[:, 1]\n",
    "fpr_rfc, tpr_rfc, _ = roc_curve(ytest, y_pred_rfc)\n",
    "auc_rfc = round(metrics.roc_auc_score(ytest, y_pred_rfc), 3)\n",
    "plt.plot(fpr_rfc, tpr_rfc, label=\"Random Forest, AUROC=\"+str(auc_rfc))\n",
    "plt.legend()\n",
    "\n",
    "model_gbc = GBC(**bestParams_GBC)\n",
    "model_gbc.fit(Xtrain, ytrain)\n",
    "y_pred_gbc = model_gbc.predict_proba(Xtest)[:, 1]\n",
    "fpr_gbc, tpr_gbc, _gbc = roc_curve(ytest, y_pred_gbc)\n",
    "auc_gbc = round(metrics.roc_auc_score(ytest, y_pred_gbc), 3)\n",
    "plt.plot(fpr_gbc, tpr_gbc, label=\"Gradient Boosting, AUROC=\"+str(auc_gbc))\n",
    "\n",
    "model_lr = LR(**bestParams_LR)\n",
    "model_lr.fit(Xtrain, ytrain)\n",
    "y_pred_lr = model_lr.predict_proba(Xtest)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(ytest, y_pred_lr)\n",
    "auc_lr = round(metrics.roc_auc_score(ytest, y_pred_lr), 3)\n",
    "plt.plot(fpr_lr, tpr_lr, label=\"Logistic Regress, AUROC=\"+str(auc_lr))\n",
    "plt.legend()\n",
    "\n",
    "model_nb = NB(**bestParams_NB)\n",
    "model_nb.fit(Xtrain, ytrain)\n",
    "y_pred_nb = model_nb.predict_proba(Xtest)[:, 1]\n",
    "fpr_nb, tpr_nb, _nb = roc_curve(ytest, y_pred_nb)\n",
    "auc_nb = round(metrics.roc_auc_score(ytest, y_pred_nb), 3)\n",
    "plt.plot(fpr_nb, tpr_nb, label=\"Naïve Bayes, AUROC=\"+str(auc_nb))\n",
    "\n",
    "model_dt = DT(**bestParams_DT)\n",
    "model_dt.fit(Xtrain, ytrain)\n",
    "y_pred_dt = model_dt.predict_proba(Xtest)[:, 1]\n",
    "fpr_dt, tpr_dt, _dt = roc_curve(ytest, y_pred_dt)\n",
    "auc_dt = round(metrics.roc_auc_score(ytest, y_pred_dt), 3)\n",
    "plt.plot(fpr_dt, tpr_dt, label=\"Decision Tree, AUROC=\"+str(auc_dt))\n",
    "\n",
    "model_knn = KNN(**bestParams_KNN)\n",
    "model_knn.fit(Xtrain, ytrain)\n",
    "y_pred_knn = model_knn.predict_proba(Xtest)[:, 1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(ytest, y_pred_knn)\n",
    "auc_knn = round(metrics.roc_auc_score(ytest, y_pred_knn), 3)\n",
    "plt.plot(fpr_knn, tpr_knn, label=\"K_Nearest Neighbor, AUROC=\"+str(auc_knn))\n",
    "plt.legend()\n",
    "\n",
    "lw = 2\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.title('ROC Curve', fontsize=20)\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('./roc_curve.png', dpi=300, bbox_inches='tight',\n",
    "            transparent=True, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting SHAP\n",
    "clf = RFC(random_state=2023, **bestParams_RFC)\n",
    "shap.initjs()\n",
    "clf.fit(X, y.values)\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X)[1]\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
